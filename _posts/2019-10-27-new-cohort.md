# A New Cohort

Tomorrow begins a new cohort in the part-time data science class I teach at General Assembly. 

I've been thinking a lot about pedagogy. This bootcamp thing is fantastic. Because of a bootcamp, I have a career, I have a side-hustle in teaching, and I have a group of [top-notch friends.](https://open.spotify.com/track/3sp3wHVuQ3CRtsZykHDtKq?si=gViW4zKfTvmFKN3jRUHBlQ)
But I also have been thinking about pedagogy.

There are drawbacks to the system, and one of the drawbacks is that given the short amount of time together, we take a path of going wide, rather than deep.

|Pros|Cons|
|---|---|
|Students learn concepts that would have taken years to uncover, in a short span| The onus is then on students to go deep, and many won't|
|By learning more difficult concepts, students pick up the less mentally challenging by osmosis| Presenting Material across [Several Learning Styles](https://www.learndash.com/7-major-learning-styles-which-one-is-you/) is non-trivial.|


I'm going to work through a series of posts describing at a deeper level, number of machine learning models.

I'll start with Linear Regression, then progress into Decision Trees, then into KNN, then Logistic Regression, Random Forests, and finally, get into Multinomial Naive Bayes.

This post will be edited, so that it serves as a sort of table of contents.

Check back soon!

- Linear Regression
- Decision Trees
- KNN
- Logistic Regression
- Random Forests
- Multinomial Naive Bayes

